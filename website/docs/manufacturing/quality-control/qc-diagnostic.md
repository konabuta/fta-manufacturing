---
id: qc-diagnostic
title: 1 変数 & 多変数の解析
---
本ページでは、**プロセス管理** と **要因探索** の 2 つのシナリオにおける **1 変数 & 多変数の解析** の技術について説明します。

---

## プロセス管理
**プロセス管理** では、製造工程を監視し、データから製造工程が正常に動いているかを判断します。

### 1 変数の解析
- 1 変数毎に閾値を設定
- 予め定義した正常データの閾値との距離の大きさで異常が発生しているかを判断

<img src={require('./images/qc-process-management-univariate.png').default} width="500" /><br />

### 多変数の解析
- 複数の変数が関係する複雑な状況
    - 単なる 1 変数毎の閾値設定だけでは異常は検知できない
- 統計的手法を用いて異常を検知

<img src={require('./images/qc-process-management-multivariate.png').default} width="500" /><br />


#### 相関関係を考慮するとは？？
<img src={require('./images/qc-process-management-correlation.png').default} width="500" /><br />

<!-- 
#### 手法例: クラスタリング
//TODO: 新規作成 -->

---

## 要因探索
製造工程のデータや検査工程のデータなどから構築される統合データを分析して、品質不良の原因を探索します。品質統合データは複数の変数で構成されているため、多変数のデータ解析の手法を用いた分析を行います。

<img src={require('./images/qc-factor-analysis.png').default} width="500" /><br />

### 手法例: 線形回帰モデルを用いた多変数の解析
ナイーブな手法として**線形回帰モデル**が挙げられます。各変数の値に重み (回帰係数) を掛け合わせたものを予測値として出力します。
<img src={require('./images/qc-factor-analysis-rl.png').default} width="500" /><br />

### 手法例: 決定木を用いた多変数の解析
**決定木**は各変数に関する条件分岐を用いて、分類や回帰を行います。
<img src={require('./images/qc-factor-analysis-dt.png').default} width="500" /><br />

### 手法例: ニューラルネットワークを用いた多変数の解析
近年、著しい進化を遂げている**ニューラルネットワーク**は、多層のネットワーク構造を用いて予測値を出力することができます。
<img src={require('./images/qc-factor-analysis-nn.png').default} width="500" /><br />


:::caution
単に品質に関する指標を予測する高精度な予測モデルを構築するだけでは不十分です。**機械学習モデルの解釈可能性・説明可能性**を考慮した開発が求められてきます。
:::

---
## 透明性の高い機械学習モデルの活用
品質管理の分野では**統計的な手法**を用いたデータ分析が行われてきました。これは解釈可能性の高いアルゴリズムを利用できるというメリットがある一方で、手法によっては制限事項や前提条件が多く、複雑なデータ・多種多様なデータ形式に対応していないという課題があります。

最先端の機械学習の手法を用いることで、複雑なデータを扱うことができます。しかしながら、その内部構造を理解するのは難しく、高い精度の予測は行えるものの、データ解析に利用できないといった課題があります。この課題に対するアプローチ方法として **解釈可能性・説明可能性** や **反実仮想説明** が挙げられます。


### 解釈可能性・説明可能性
まず主流なアプローチ方法として機械学習モデルの解釈可能性・説明可能性を利用することが挙げられます。

**解釈性可能性** の高い機械学習モデルとは、品質管理の分野で長年使われてきた統計的手法 (線形回帰モデル、決定木 etc) のようにモデルの構造が解釈しやすいモデルを指します。更に近年は **GA2M** のように、統計的な手法以外でも高い精度を実現できる解釈性可能性の高いモデルが開発されています。

また **説明可能性** が高いとは、機械学習モデルがアウトプットした予測に対して、なぜその予測を出力したのかを説明できることを指します。このケースでは機械学習モデルを Blackbox として扱います。つまり、内部の構造は考慮せず、機械学習モデルに対する入力と予測値の関係性を見ます。**SHAP** などの手法が開発されています。

#### 参考情報
- [解釈可能性 & 説明可能性](https://konabuta.github.io/azure-machine-learning-playbook/docs/azureml/responsible-ai/rai-interpretability-explainability)
- [GitHub - SHAP](https://github.com/slundberg/shap)

### 反実仮想説明
**反実仮想説明** は、機械学習モデルの予測が変化する (増加/減少する or 反対になる) 特徴量のサンプルを提示することで機械学習モデルを説明しようとする説明性の手法です。

例えば、品質を予測するモデルを利用したところ、品質が悪いという予測値が返されたとします。反実仮想説明は、この予測値を変化させるため、つまり品質を良くするために、特徴量をどのように変化されば良いのかを提示することができます。

#### 参考情報
- [反実仮想説明](https://konabuta.github.io/azure-machine-learning-playbook/docs/azureml/responsible-ai/rai-counterfactual-explanation)
