//TODO: [Azure Machine Learning Playbook - モデルのデバッグ](https://konabuta.github.io/azure-machine-learning-playbook/docs/azureml/responsible-ai/rai-tech-debugging) に記載していく

//TODO: Azure Machine Learning Playbook の構成を変更する
//現状 --> "モデルのデバッグ" のページに Error Analysis、Fairness、Model interpretability、Counterfactual explanation の説明
//変更後 (予定) -->
// モデルデバッグ
// - 解釈可能性と説明可能性
//  - 概要 (背景、考え方)
//  - 手法 (技術詳細)
// - Responsible AI Toolbox




# 解釈可能性と説明可能性の概要

## 解釈可能性と説明可能性の背景
住宅ローンの審査で機械学習モデルが利用されるシーンを考えてみます。

//TODO: 機械学習プロセスの流れの図を追加する

単に機械学習モデルを構築しその精度を確認するでは不十分なケースが多いです。

//TODO: コメント付きの機械学習プロセスの流れの図を追加する


### AI・機械学習の社会実装の難しさ
原因は多岐に渡りますが、AI・機械学習の社会実装の難しさの一つに、AI・機械学習モデルの解釈性・説明性が挙げられます。

- モデルの予測値の根拠が理解できない
- モデルの品質が不透明
- モデルの改善方法がわからない

といった点が挙げられます。特に従来の統計的手法に比べ、近年の機械学習モデルは高精度である一方で、解釈性・説明性が低い傾向にあります。

### 人間中心の AI・機械学習のシステム
//TODO: 各ステークホルダーからのコメントがついた図を追加する


## 責任のある AI
//TODO: Microsoft の責任のある AI の原則の図を追加する

## 大局的と局所的
//TODO: 大局的と局所的の図を追加する
- 大域的
    - 機械学習モデルの総合的な解釈・説明

- 局所的
    - あるデータに対する機械学習モデルの予測値の挙動についての解釈・説明



## ユースケース
### 人間の能力を拡張する
//TODO: 人間の能力を拡張する図を追加する

### AI・機械学習モデルを評価する
//TODO: AI・機械学習モデルを評価する図を追加する

### AI・機械学習モデルをデバッグする
//TODO: AI・機械学習モデルをデバッグする図を追加する

## 2 つのアプローチ方法 (解釈可能性 VS 説明可能性)
### 解釈可能性とは？
**解釈可能性** の高い機械学習モデルとは、予測値に至るまでの計算プロセス・仕組みが解釈できるモデルを指します。
#### 手法例
- 線形回帰モデル
- 決定木
- 一般化線形モデル
- 一般化加法モデル

### 説明可能性とは？
**説明可能性** の高い機械学習モデルとは、モデルがアウトプットした予測に対して、なぜその予測値を出力したのかを説明できるモデルを指します。機械学習モデルを **BlackBox** として扱い、内部の構造は見ずに、モデルに対する入力と予測値の関係を見ます。
#### 手法例
- ランダムフォレスト
- 勾配ブースティング
- ニューラルネットワーク

### 解釈可能性と性能のトレードオフ
//TODO: 縦軸 Accuracy、横軸 Interpretability の図を追加する

//TODO: 解釈可能性と説明可能性がそれぞれどうアプローチしているのかを説明している図を追加する

    